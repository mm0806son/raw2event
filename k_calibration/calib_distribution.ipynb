{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e81da236",
   "metadata": {},
   "source": [
    "# $k$ Calibration\n",
    "\n",
    "According to the methods presented by Lin *et al.*,  output `*_fit_results.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e89538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math, os, json, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import invgauss, levy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de853c",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2105d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PREFIX = 'RAW'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "MEAN_BINS = 50\n",
    "DIFF_BINS = 50\n",
    "COUNT_THRESHOLD = 100\n",
    "MIN_EVENTS_PER_GROUP = 50\n",
    "\n",
    "# τ filter\n",
    "MAX_INTERVAL_US = 50000   # 50 ms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7099c",
   "metadata": {},
   "source": [
    "## 2. Read event tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19707ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dvs_events(pt_path, device='cuda'):\n",
    "    \"\"\"Load and process DVS event data.\n",
    "\n",
    "    Args:\n",
    "        pt_path (str): Path to the .pt file\n",
    "        device (str): Device to load the data on ('cuda' or 'cpu')\n",
    "\n",
    "    Returns:\n",
    "        tuple: (ts, x, y, p, prev_lum, next_lum, frame_dt)\n",
    "            - ts: Timestamps (in seconds)\n",
    "            - x, y: Pixel coordinates\n",
    "            - p: Polarity\n",
    "            - prev_lum, next_lum: Luminance from previous and next frames\n",
    "            - frame_dt: Frame time interval (in seconds)\n",
    "    \"\"\"\n",
    "    data = torch.load(pt_path, map_location=device)\n",
    "    if data.dim() != 2 or data.size(1) != 7:\n",
    "        raise ValueError('Expected shape (N, 7), got {}'.format(data.size()))\n",
    "\n",
    "    timestamp_us, x, y, p, prev_lum, next_lum, frame_dt_us = data.t().cpu().numpy()\n",
    "\n",
    "    # Convert data types\n",
    "    timestamp_us = timestamp_us.astype(np.float64)\n",
    "    frame_dt_us = frame_dt_us.astype(np.float64)\n",
    "    prev_lum = prev_lum.astype(np.float32)\n",
    "    next_lum = next_lum.astype(np.float32)\n",
    "\n",
    "    df = pd.DataFrame(dict(\n",
    "        timestamp_us=timestamp_us,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        p=p,\n",
    "        prev_lum=prev_lum,\n",
    "        next_lum=next_lum,\n",
    "        frame_dt_us=frame_dt_us\n",
    "    ))\n",
    "    \n",
    "    df_on  = df[df.p == 1]\n",
    "    df_off = df[df.p == 0]\n",
    "    \n",
    "    return df_on, df_off\n",
    "\n",
    "# Load ON and OFF event DataFrames from file\n",
    "pt_path = Path('../k_calib_20250509/calib_1/frames_analysis_full/events_with_luminance_raw.pt') \n",
    "df_on, df_off = load_dvs_events(pt_path, DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4fc745",
   "metadata": {},
   "source": [
    "## 3. Calculate event interval τ, mean luminance $\\bar L$ and luminance difference $\\Delta L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400574a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_arrays(sub):\n",
    "    \"\"\"Convert a sub DataFrame into the 6 ndarrays required by compute_event_intervals\"\"\"\n",
    "    return (\n",
    "        sub.timestamp_us.values,\n",
    "        sub.x.values,\n",
    "        sub.y.values,\n",
    "        sub.prev_lum.values,\n",
    "        sub.next_lum.values,\n",
    "        sub.frame_dt_us.values\n",
    "    )\n",
    "\n",
    "ts_on,  x_on,  y_on,  prev_on,  next_on,  dtframe_on  = df_to_arrays(df_on)\n",
    "ts_off, x_off, y_off, prev_off, next_off, dtframe_off = df_to_arrays(df_off)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f80224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_event_intervals(ts, x, y, prev_lum, next_lum, frame_dt, max_interval_us=1e10):\n",
    "    \"\"\"Compute time intervals and luminance changes between consecutive events.\n",
    "\n",
    "    Args:\n",
    "        ts (np.ndarray): Timestamp array (in microseconds)\n",
    "        x, y (np.ndarray): Pixel coordinate arrays\n",
    "        prev_lum, next_lum (np.ndarray): Luminance values from previous and next frames\n",
    "        frame_dt (np.ndarray): Frame time interval array (in microseconds)\n",
    "        max_interval_us (float): Maximum allowed time interval between events (in µs)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (tau, Lbar, dL, dt)\n",
    "            - tau: Time interval between consecutive events (in µs)\n",
    "            - Lbar: Mean luminance\n",
    "            - dL: Luminance difference\n",
    "            - dt: Corresponding frame interval (in µs)\n",
    "    \"\"\"\n",
    "    # Sort by (x, y, ts)\n",
    "    order = np.lexsort((ts, y, x))\n",
    "    ts_sorted = ts[order]\n",
    "    x_sorted = x[order]\n",
    "    y_sorted = y[order]\n",
    "    prev_sorted = prev_lum[order]\n",
    "    next_sorted = next_lum[order]\n",
    "    frame_dt_sorted = frame_dt[order]\n",
    "    \n",
    "    # Find index of previous event for the same pixel\n",
    "    N = len(ts_sorted)\n",
    "    prev_idx = np.full(N, -1, dtype=np.int64)\n",
    "    mask_same = (x_sorted[1:] == x_sorted[:-1]) & (y_sorted[1:] == y_sorted[:-1])\n",
    "    prev_idx[1:][mask_same] = np.arange(N - 1)[mask_same]\n",
    "    \n",
    "    valid = prev_idx != -1\n",
    "    # Compute τ\n",
    "    tau = ts_sorted - ts_sorted[prev_idx]\n",
    "    tau = tau[valid]\n",
    "    \n",
    "    # Filter out abnormal τ values\n",
    "    valid_tau = (tau > 0) & (tau < max_interval_us)\n",
    "    tau = tau[valid_tau]\n",
    "    \n",
    "    # Compute luminance values\n",
    "    Lbar = (prev_sorted[prev_idx] + next_sorted[prev_idx]) / 2\n",
    "    Lbar = Lbar[valid][valid_tau]\n",
    "    dL = (next_sorted[prev_idx] - prev_sorted[prev_idx])[valid][valid_tau]\n",
    "    \n",
    "    # Also extract corresponding frame interval Δt\n",
    "    dt = frame_dt_sorted[prev_idx][valid][valid_tau]\n",
    "    \n",
    "    return tau, Lbar, dL, dt\n",
    "\n",
    "# Compute intervals for ON events\n",
    "tau_on, Lbar_on, dL_on, dt_on = compute_event_intervals(\n",
    "    ts_on, x_on, y_on, prev_on, next_on, dtframe_on, MAX_INTERVAL_US\n",
    ")\n",
    "\n",
    "# Compute intervals for OFF events\n",
    "tau_off, Lbar_off, dL_off, dt_off = compute_event_intervals(\n",
    "    ts_off, x_off, y_off, prev_off, next_off, dtframe_off, MAX_INTERVAL_US\n",
    ")\n",
    "\n",
    "print(\"Number of valid ON event pairs:\", len(tau_on))\n",
    "print(\"Number of valid OFF event pairs:\", len(tau_off))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc4bbd",
   "metadata": {},
   "source": [
    "## 4. Automatically estimate valid luminance range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bcc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_valid_ranges(Lbar, dL, mean_bins=30, diff_bins=30, count_threshold=100):\n",
    "    \"\"\"Estimate valid ranges for luminance and luminance difference.\n",
    "\n",
    "    Args:\n",
    "        Lbar (np.ndarray): Array of mean luminance\n",
    "        dL (np.ndarray): Array of luminance differences\n",
    "        mean_bins (int): Number of bins for mean luminance\n",
    "        diff_bins (int): Number of bins for luminance difference\n",
    "        count_threshold (int): Minimum number of events for a valid bin\n",
    "\n",
    "    Returns:\n",
    "        tuple: (L_min, L_max, dL_min, dL_max)\n",
    "            - L_min, L_max: Valid range of mean luminance\n",
    "            - dL_min, dL_max: Valid range of luminance difference\n",
    "    \"\"\"\n",
    "    H, edges_L, edges_dL = np.histogram2d(Lbar, dL, bins=[mean_bins, diff_bins])\n",
    "    \n",
    "    # Find bins where count > count_threshold\n",
    "    idx_valid = np.where(H > count_threshold)\n",
    "    if len(idx_valid[0]) == 0:\n",
    "        L_min, L_max = Lbar.min(), Lbar.max()\n",
    "        dL_min, dL_max = dL.min(), dL.max()\n",
    "    else:\n",
    "        L_min = edges_L[idx_valid[0]].min()\n",
    "        L_max = edges_L[idx_valid[0] + 1].max()\n",
    "        dL_min = edges_dL[idx_valid[1]].min()\n",
    "        dL_max = edges_dL[idx_valid[1] + 1].max()\n",
    "\n",
    "    return L_min, L_max, dL_min, dL_max\n",
    "\n",
    "# Estimate valid ranges for ON events\n",
    "L_min_on, L_max_on, dL_min_on, dL_max_on = estimate_valid_ranges(\n",
    "    Lbar_on, dL_on, \n",
    "    mean_bins=MEAN_BINS, \n",
    "    diff_bins=DIFF_BINS, \n",
    "    count_threshold=COUNT_THRESHOLD\n",
    ")\n",
    "\n",
    "# Estimate valid ranges for OFF events\n",
    "L_min_off, L_max_off, dL_min_off, dL_max_off = estimate_valid_ranges(\n",
    "    Lbar_off, dL_off, \n",
    "    mean_bins=MEAN_BINS, \n",
    "    diff_bins=DIFF_BINS, \n",
    "    count_threshold=COUNT_THRESHOLD\n",
    ")\n",
    "\n",
    "print('Valid L_on range:', L_min_on, L_max_on)\n",
    "print('Valid dL_on range:', dL_min_on, dL_max_on)\n",
    "print('Valid L_off range:', L_min_off, L_max_off)\n",
    "print('Valid dL_off range:', dL_min_off, dL_max_off)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e2624",
   "metadata": {},
   "source": [
    "## 5. Bin and fit inverse Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c827a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_event_distributions(Lbar, dL, tau, L_min, L_max, dL_min, dL_max, p,\n",
    "                            mean_bins=50, diff_bins=50, min_events_per_group=200):\n",
    "    \"\"\"Fit distributions to event data and return the results.\n",
    "\n",
    "    Args:\n",
    "        Lbar (np.ndarray): Array of mean luminance\n",
    "        dL (np.ndarray): Array of luminance differences\n",
    "        tau (np.ndarray): Array of event time intervals\n",
    "        L_min, L_max (float): Valid range for mean luminance\n",
    "        dL_min, dL_max (float): Valid range for luminance difference\n",
    "        mean_bins (int): Number of bins for mean luminance\n",
    "        diff_bins (int): Number of bins for luminance difference\n",
    "        min_events_per_group (int): Minimum number of events per group\n",
    "        output_prefix (str): Prefix for output file names\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the fitted results\n",
    "    \"\"\"\n",
    "    # Create bin grids\n",
    "    L_bins = np.linspace(L_min, L_max, mean_bins + 1)\n",
    "    dL_bins = np.linspace(dL_min, dL_max, diff_bins + 1)\n",
    "\n",
    "    MU_THRESHOLD_KDL = 1e-4  # Drift rate |k_dL| < 1e-4 is treated as zero\n",
    "\n",
    "    results = []\n",
    "    for i in range(mean_bins):\n",
    "        for j in range(diff_bins):\n",
    "            mask = (Lbar >= L_bins[i]) & (Lbar < L_bins[i + 1]) & \\\n",
    "                   (dL >= dL_bins[j]) & (dL < dL_bins[j + 1])\n",
    "            if mask.sum() < min_events_per_group:\n",
    "                continue\n",
    "\n",
    "            tau_bin = tau[mask]  # Use only the data in the current bin\n",
    "            shape, loc, scale = invgauss.fit(tau_bin, floc=0)\n",
    "\n",
    "            mu_hat = shape * scale           # Corresponds to |Θ| / μ in the paper\n",
    "            lambda_hat = shape / scale       # Corresponds to Θ² / σ² in the paper\n",
    "            if p == 1:\n",
    "                mu = -1.0 / mu_hat           # Negate for ON events\n",
    "            else:                             # For OFF events\n",
    "                mu = 1.0 / mu_hat\n",
    "            sigma = 1 / math.sqrt(lambda_hat)\n",
    "\n",
    "            if mu_hat < MU_THRESHOLD_KDL:\n",
    "                # ----- Switch to Lévy fitting -----\n",
    "                loc_lv, scale_lv = levy.fit(tau_bin, floc=0)\n",
    "                mu = 0.0                     # μ → 0\n",
    "                mu_hat = 0.0\n",
    "                lambda_hat = scale_lv        # λ = c  (Θ² / σ²)\n",
    "                sigma = 1.0 / math.sqrt(lambda_hat)\n",
    "\n",
    "            results.append({\n",
    "                \"P\": p,\n",
    "                'MeanMin': L_bins[i],\n",
    "                'MeanMax': L_bins[i + 1],\n",
    "                'DiffMin': dL_bins[j],\n",
    "                'DiffMax': dL_bins[j + 1],\n",
    "                'MuHat': mu_hat,\n",
    "                'LambdaHat': lambda_hat,\n",
    "                'Mu': mu,\n",
    "                'Sigma': sigma,\n",
    "                'Count': mask.sum()\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Fit ON events\n",
    "df_results_on = fit_event_distributions(\n",
    "    Lbar=Lbar_on,\n",
    "    dL=dL_on,\n",
    "    tau=tau_on,\n",
    "    L_min=L_min_on,\n",
    "    L_max=L_max_on,\n",
    "    dL_min=dL_min_on,\n",
    "    dL_max=dL_max_on,\n",
    "    p=1,\n",
    "    mean_bins=MEAN_BINS,\n",
    "    diff_bins=DIFF_BINS,\n",
    "    min_events_per_group=MIN_EVENTS_PER_GROUP\n",
    ")\n",
    "\n",
    "# Fit OFF events\n",
    "df_results_off = fit_event_distributions(\n",
    "    Lbar=Lbar_off,\n",
    "    dL=dL_off,\n",
    "    tau=tau_off,\n",
    "    L_min=L_min_off,\n",
    "    L_max=L_max_off,\n",
    "    dL_min=dL_min_off,\n",
    "    dL_max=dL_max_off,\n",
    "    p=0,\n",
    "    mean_bins=MEAN_BINS,\n",
    "    diff_bins=DIFF_BINS,\n",
    "    min_events_per_group=MIN_EVENTS_PER_GROUP\n",
    ")\n",
    "\n",
    "# Combine and save\n",
    "df_results = pd.concat([df_results_on, df_results_off], ignore_index=True)\n",
    "out_csv = f'{OUTPUT_PREFIX}_fit_results.csv'\n",
    "df_results.to_csv(out_csv, index=False)\n",
    "print('Saved:', out_csv, 'Number of bins:', len(df_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b46652",
   "metadata": {},
   "source": [
    "# Process all subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c288f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pt(pt_path, mode):\n",
    "    \"\"\"Process a single .pt file and return the fitting result.\n",
    "\n",
    "    Args:\n",
    "        pt_path (Path): Path to the .pt file\n",
    "        mode (str): Data mode ('RAW' or 'RGB')\n",
    "    \"\"\"\n",
    "    df_on, df_off= load_dvs_events(pt_path, DEVICE)\n",
    "    ts_on,  x_on,  y_on,  prev_on,  next_on,  dtframe_on  = df_to_arrays(df_on)\n",
    "    ts_off, x_off, y_off, prev_off, next_off, dtframe_off = df_to_arrays(df_off)\n",
    "    tau_on,  Lbar_on,  dL_on,  dt_on  = compute_event_intervals(\n",
    "        ts_on,  x_on,  y_on,  prev_on,  next_on,  dtframe_on,  MAX_INTERVAL_US\n",
    "    )\n",
    "    tau_off, Lbar_off, dL_off, dt_off = compute_event_intervals(\n",
    "        ts_off, x_off, y_off, prev_off, next_off, dtframe_off, MAX_INTERVAL_US\n",
    "    )\n",
    "    L_min_on, L_max_on, dL_min_on, dL_max_on = estimate_valid_ranges(\n",
    "        Lbar_on, dL_on, \n",
    "        mean_bins=MEAN_BINS, \n",
    "        diff_bins=DIFF_BINS, \n",
    "        count_threshold=COUNT_THRESHOLD\n",
    "    )\n",
    "    L_min_off, L_max_off, dL_min_off, dL_max_off = estimate_valid_ranges(\n",
    "        Lbar_off, dL_off, \n",
    "        mean_bins=MEAN_BINS, \n",
    "        diff_bins=DIFF_BINS, \n",
    "        count_threshold=COUNT_THRESHOLD\n",
    "    )\n",
    "    df_results_on = fit_event_distributions(\n",
    "        Lbar=Lbar_on,\n",
    "        dL=dL_on,\n",
    "        tau=tau_on,\n",
    "        L_min=L_min_on,\n",
    "        L_max=L_max_on,\n",
    "        dL_min=dL_min_on,\n",
    "        dL_max=dL_max_on,\n",
    "        p=1,\n",
    "        mean_bins=MEAN_BINS,\n",
    "        diff_bins=DIFF_BINS,\n",
    "        min_events_per_group=MIN_EVENTS_PER_GROUP\n",
    "    )\n",
    "    df_results_off = fit_event_distributions(\n",
    "        Lbar=Lbar_off,\n",
    "        dL=dL_off,\n",
    "        tau=tau_off,\n",
    "        L_min=L_min_off,\n",
    "        L_max=L_max_off,\n",
    "        dL_min=dL_min_off,\n",
    "        dL_max=dL_max_off,\n",
    "        p=0,\n",
    "        mean_bins=MEAN_BINS,\n",
    "        diff_bins=DIFF_BINS,\n",
    "        min_events_per_group=MIN_EVENTS_PER_GROUP\n",
    "    )\n",
    "    # 合并 ON+OFF 回传\n",
    "    return pd.concat([df_results_on, df_results_off], ignore_index=True)\n",
    "\n",
    "\n",
    "# 顶层实验输出目录\n",
    "ROOT_DIR = Path('../data')\n",
    "\n",
    "for mode in ['RAW', 'RGB']:                        # 2 different bit‑depth\n",
    "    all_dfs = []\n",
    "    # search for .pt\n",
    "    for pt_path in ROOT_DIR.rglob(f'events_with_luminance_{mode.lower()}.pt'):\n",
    "        try:\n",
    "            df_one = process_pt(pt_path, mode)     # process single file\n",
    "            all_dfs.append(df_one)\n",
    "            print('processed', pt_path)\n",
    "        except Exception as e:\n",
    "            print('skip', pt_path, e)\n",
    "\n",
    "    if not all_dfs:\n",
    "        continue\n",
    "\n",
    "    # merge\n",
    "    merged = pd.concat(all_dfs, ignore_index=True)\n",
    "    merged.to_csv(f'{mode}_fit_results_all.csv', index=False)\n",
    "    print(f'{mode}_fit_results_all.csv written, buckets =', len(merged))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DVS-Voltmeter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
