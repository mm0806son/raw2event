{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Variable Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook processes data from RGB, RAW, and event camera sensor.\n",
    "\n",
    "Functions:\n",
    "1. Loads RGB, RAW, and DVS frames and event streams.\n",
    "2. Aligns timestamps across different sensor modalities for accurate comparison.\n",
    "4. Detects target regions (i.e., AprilTag, Barbara tag).\n",
    "5. Crops and filters event data based on detected regions.\n",
    "6. Visualizes frames, event data, cropping results, and target trajectories.\n",
    "7. Analyzes event statistics, including per-pixel time intervals and frequency spectrum.\n",
    "8. Playback for filtered event data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dv_processing as dv\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import mmap\n",
    "import aiofiles\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.append('./src/process_data')  # Add module path\n",
    "import process_data.file_read as file_read\n",
    "import process_data.dvs_generate as dvs_generate\n",
    "import process_data.tag_detector as tag_detector\n",
    "import process_data.event_filter as event_filter\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "INPUT_FOLDER = \"\"  # Replace with your folder path\n",
    "FILE_SUFFIX = \"170406\"  # Replace with your file suffix\n",
    "\n",
    "# Find matching files\n",
    "try:\n",
    "    files = file_read.find_matching_files(INPUT_FOLDER, FILE_SUFFIX)        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Width and height used when reading pi data\n",
    "PI_IMAGE_WIDTH = 692\n",
    "PI_IMAGE_HEIGHT = 520\n",
    "\n",
    "# K values used for generating simulated event data\n",
    "# Used for generating raw simulated event data (default is dvs original k)\n",
    "k_values_raw = [2.388, 4.166e-7, 1.541e-6, 9.768e-8, 1.466e-11, 9.824e-6]\n",
    "# Used for generating rgb simulated event data (default is dvs original k)\n",
    "k_values_rgb = [5.332474147628972,0.9003332027266823,8.288263352543993e-06,1.0992397172828087e-07,3.302652963977818e-09,1.1012444038716504e-07] \n",
    "\n",
    "# Ratio for tag detection trajectory\n",
    "TAG_REF_WIDTH = 287      # AprilTag reference width (pixels)\n",
    "BARBARA_REF_SIZE = 861   # Barbara reference side length (pixels)\n",
    "BARBARA_GAP = 82         # Gap between Barbara and tag (pixels)\n",
    "margin_ratio = 0.03\n",
    "\n",
    "# Number of threads\n",
    "N_WORKERS = 4 \n",
    "\n",
    "# Batch size for filtering event data\n",
    "BATCH_SIZE_FOR_EVENT = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#                      Data Loading Section                #\n",
    "############################################################\n",
    "dv_frames, dv_frames_timestamps = file_read.load_frames(files['dv'])\n",
    "dv_events_tensor = file_read.load_events(files['dv'])\n",
    "rgb_frames = file_read.read_rgb_frames(files['rgb_frames'], PI_IMAGE_HEIGHT, PI_IMAGE_WIDTH)\n",
    "raw_frames = file_read.read_raw_frames(files['raw_frames'], PI_IMAGE_HEIGHT, PI_IMAGE_WIDTH)\n",
    "pi_timestamps, real_timestamps = file_read.read_metadata(files['metadata'])\n",
    "\n",
    "############################################################\n",
    "#                   Generate Simulated Event Data          #\n",
    "############################################################\n",
    "# Single-threaded RGB event generation\n",
    "rgb_events_tensor = dvs_generate.generate_events_tensor(\n",
    "pi_timestamps,  # PI camera timestamps\n",
    "rgb_frames,     # RGB frame data\n",
    "is_rgb=True,    # Mark as RGB data\n",
    "k_values=k_values_rgb\n",
    ")\n",
    "# Single-threaded RAW event generation\n",
    "raw_events_tensor = dvs_generate.generate_events_tensor(\n",
    "pi_timestamps,  # PI camera timestamps\n",
    "raw_frames,     # RAW frame data\n",
    "is_rgb=False,   # Mark as non-RGB (i.e., RAW) data\n",
    "k_values=k_values_raw\n",
    ")\n",
    "\n",
    "############################################################\n",
    "#                      Time Alignment                      #\n",
    "############################################################\n",
    "# Calculate time offset\n",
    "time_offset = file_read.calculate_time_offset(pi_timestamps, real_timestamps)\n",
    "# Adjust DV frame timestamps\n",
    "dv_frames_timestamps = dv_frames_timestamps - time_offset\n",
    "# Adjust DV event timestamps\n",
    "dv_events_tensor[:, 0] = dv_events_tensor[:, 0] - time_offset\n",
    "\n",
    "\n",
    "############################################################\n",
    "#                   Trajectory Data (Parallel)             #\n",
    "############################################################\n",
    "# Construct parameter lists\n",
    "margin_ratios = [margin_ratio] * N_WORKERS\n",
    "tag_ref_widths = [TAG_REF_WIDTH] * N_WORKERS\n",
    "barbara_ref_sizes = [BARBARA_REF_SIZE] * N_WORKERS\n",
    "barbara_gaps = [BARBARA_GAP] * N_WORKERS\n",
    "is_raws_rgb = [False] * N_WORKERS\n",
    "is_raws_raw = [True] * N_WORKERS\n",
    "\n",
    "rgb_frame_batches = tag_detector.split_batches(rgb_frames.numpy(), N_WORKERS)\n",
    "raw_frame_batches = tag_detector.split_batches(raw_frames.numpy(), N_WORKERS)\n",
    "ts_batches = tag_detector.split_batches(pi_timestamps, N_WORKERS)\n",
    "\n",
    "dv_frame_batches = tag_detector.split_batches(dv_frames.numpy(), N_WORKERS)\n",
    "dv_ts_batches = tag_detector.split_batches(dv_frames_timestamps, N_WORKERS)\n",
    "\n",
    "# Batch get RGB frame crop box information\n",
    "# Multi-threaded batch processing with progress display\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as executor:\n",
    "    rgb_all_results = []\n",
    "    for batch_result in tqdm(\n",
    "        executor.map(\n",
    "            tag_detector.process_batch,\n",
    "            rgb_frame_batches, ts_batches,\n",
    "            margin_ratios, tag_ref_widths, barbara_ref_sizes, barbara_gaps, is_raws_rgb\n",
    "        ),\n",
    "        total=N_WORKERS\n",
    "    ):\n",
    "        rgb_all_results.append(batch_result)\n",
    "\n",
    "rgb_crops_info = [item for batch in rgb_all_results for item in batch]# Merge all results\n",
    "rgb_crops_info.sort(key=lambda x: x[2])  # Sort by timestamp\n",
    "\n",
    "\n",
    "# Batch get RAW frame crop box information\n",
    "# Multi-threaded batch processing with progress display\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as executor:\n",
    "    raw_all_results = []\n",
    "    for batch_result in tqdm(\n",
    "        executor.map(\n",
    "            tag_detector.process_batch,\n",
    "            raw_frame_batches, ts_batches,\n",
    "            margin_ratios, tag_ref_widths, barbara_ref_sizes, barbara_gaps, is_raws_raw\n",
    "        ),\n",
    "        total=N_WORKERS\n",
    "    ):\n",
    "        raw_all_results.append(batch_result)\n",
    "\n",
    "raw_crops_info = [item for batch in raw_all_results for item in batch]# Merge all results\n",
    "raw_crops_info.sort(key=lambda x: x[2])  # Sort by timestamp\n",
    "\n",
    "# Batch get DV frame crop box information\n",
    "# Multi-threaded batch processing with progress display\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as executor:\n",
    "    dv_all_results = []\n",
    "    for batch_result in tqdm(\n",
    "        executor.map(\n",
    "            tag_detector.process_batch,\n",
    "            dv_frame_batches, dv_ts_batches,\n",
    "            margin_ratios, tag_ref_widths, barbara_ref_sizes, barbara_gaps, is_raws_rgb\n",
    "        ),\n",
    "        total=N_WORKERS\n",
    "    ):\n",
    "        dv_all_results.append(batch_result)\n",
    "\n",
    "dv_crops_info = [item for batch in dv_all_results for item in batch]# Merge all results\n",
    "dv_crops_info.sort(key=lambda x: x[2])  # x[2] is timestamp# Sort by timestamp\n",
    "# Column 0: barbara_info - Contains detected Barbara tag information, such as polygon vertices, rotation angle, center point, etc.\n",
    "# Column 1: tag_info - Contains detected AprilTag information, such as ID, position, etc.\n",
    "# Column 2: timestamp - Current frame timestamp\n",
    "\n",
    "\n",
    "############################################################\n",
    "#                   Filter Event Data                      #\n",
    "############################################################\n",
    "# Assume box_size is a tuple (w, h)\n",
    "def round_up_to_10(x):\n",
    "    return int(math.ceil(x / 10.0) * 10)\n",
    "\n",
    "# Round up to the nearest multiple of 10 as the maximum side length for filtering event data\n",
    "RGB_BOX_SIZE_FOR_EVENT = round_up_to_10(max(rgb_crops_info[0][0]['polygon'].ptp(axis=0)))\n",
    "RAW_BOX_SIZE_FOR_EVENT = round_up_to_10(max(raw_crops_info[0][0]['polygon'].ptp(axis=0)))\n",
    "DV_BOX_SIZE_FOR_EVENT = round_up_to_10(max(dv_crops_info[0][0]['polygon'].ptp(axis=0)))\n",
    "\n",
    "# RGB event filtering\n",
    "# Use parallel processing function\n",
    "filtered_events_rgb = event_filter.filter_events_parallel(\n",
    "    events_tensor=rgb_events_tensor,  # Your event data\n",
    "    crops_info=rgb_crops_info,        # Crop box information\n",
    "    target_size=RGB_BOX_SIZE_FOR_EVENT,  # Target crop box size\n",
    "    transform=True,                    # Whether to transform coordinates\n",
    "    batch_size=BATCH_SIZE_FOR_EVENT,                # Number of events processed per batch\n",
    "    n_workers=N_WORKERS                       # Number of parallel processes\n",
    ")\n",
    "\n",
    "# RAW event filtering\n",
    "# Use parallel processing function\n",
    "filtered_events_raw = event_filter.filter_events_parallel(\n",
    "    events_tensor=raw_events_tensor,  # Your event data\n",
    "    crops_info=raw_crops_info,        # Crop box information\n",
    "    target_size=RAW_BOX_SIZE_FOR_EVENT,  # Target crop box size\n",
    "    transform=True,                    # Whether to transform coordinates\n",
    "    batch_size=BATCH_SIZE_FOR_EVENT,                # Number of events processed per batch\n",
    "    n_workers=N_WORKERS                       # Number of parallel processes\n",
    ")\n",
    "\n",
    "# DV event filtering\n",
    "# Use parallel processing function\n",
    "filtered_events_dv = event_filter.filter_events_parallel(\n",
    "    events_tensor=dv_events_tensor,  # Your event data\n",
    "    crops_info=dv_crops_info,        # Crop box information\n",
    "    target_size=DV_BOX_SIZE_FOR_EVENT,  # Target crop box size\n",
    "    transform=True,                    # Whether to transform coordinates\n",
    "    batch_size=BATCH_SIZE_FOR_EVENT,                # Number of events processed per batch\n",
    "    n_workers=N_WORKERS                       # Number of parallel processes\n",
    ")\n",
    "\n",
    "\n",
    "############################################################\n",
    "#                      End                                 #\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "plt.figure(figsize=(15, 6))  # Adjust overall figure size\n",
    "\n",
    "# First subplot: RAW frame\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
    "plt.imshow(raw_frames[0].numpy(), cmap='gray')\n",
    "plt.title('RAW Frame 0')\n",
    "plt.axis('off')  # Turn off axes\n",
    "\n",
    "# Second subplot: RGB frame\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
    "plt.imshow(rgb_frames[0].numpy())\n",
    "plt.title('RGB Frame 0')\n",
    "plt.axis('off')  # Turn off axes\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Interval Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import process_data.interval_fit as interval_fit\n",
    "import importlib\n",
    "importlib.reload(interval_fit)\n",
    "\n",
    "\n",
    "num_pixels_rgb, dt_rgb, mu_rgb, sigma_rgb = interval_fit.analyze_per_pixel_event_intervals_combined(\n",
    "    events=filtered_events_rgb,\n",
    "    min_events_per_pixel=10,         # For example, each pixel needs at least 10 events\n",
    "    max_dt_us_for_plot=100000,          # For example, only look at intervals below 200 microseconds when plotting\n",
    "    plot_bins=100,\n",
    "    type='RGB'\n",
    ")\n",
    "plt.show()  # Display the figure\n",
    "\n",
    "num_pixels_raw, dt_raw, mu_raw, sigma_raw = interval_fit.analyze_per_pixel_event_intervals_combined(\n",
    "    events=filtered_events_raw,\n",
    "    min_events_per_pixel=10,         # For example, each pixel needs at least 10 events\n",
    "    max_dt_us_for_plot=100000,          # For example, only look at intervals below 200 microseconds when plotting\n",
    "    plot_bins=100,\n",
    "    type='RAW'\n",
    ")\n",
    "plt.show()  # Display the figure\n",
    "\n",
    "\n",
    "num_pixels_dv, dt_dv, mu_dv, sigma_dv = interval_fit.analyze_per_pixel_event_intervals_combined(\n",
    "    events=filtered_events_dv,\n",
    "    min_events_per_pixel=10,         # For example, each pixel needs at least 10 events\n",
    "    max_dt_us_for_plot=100000,          # For example, only look at intervals below 200 microseconds when plotting\n",
    "    plot_bins=100,\n",
    "    type='DV'\n",
    ")\n",
    "plt.show()  # Display the figure\n",
    "\n",
    "import process_data.interval_fit as interval_fit\n",
    "import importlib\n",
    "importlib.reload(interval_fit)\n",
    "\n",
    "# Frequency spectrum (time intervals)\n",
    "results = interval_fit.analyze_event_frequency_spectrum(\n",
    "    filtered_events_raw,          # Event data\n",
    "    max_freq_hz=100,              # Maximum frequency limit\n",
    "    bins=50                       # Number of histogram bins\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# FFT spectrum\n",
    "fft_results = interval_fit.analyze_event_fft_spectrum(\n",
    "    filtered_events_raw,\n",
    "    sampling_rate=1000,   # Sampling rate (Hz)\n",
    "    max_freq_hz=100       # Maximum frequency limit\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Box Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detector\n",
    "detector = tag_detector.create_detector()\n",
    "\n",
    "# Process RGB frame\n",
    "barbara_info_rgb, cropped_rgb, ts_rgb = tag_detector.process_frame(\n",
    "    rgb_frames[0].numpy(), pi_timestamps[0], detector, \n",
    "    margin_ratio=margin_ratio, \n",
    "    tag_ref_width=TAG_REF_WIDTH, \n",
    "    barbara_ref_size=BARBARA_REF_SIZE, \n",
    "    barbara_gap=BARBARA_GAP,\n",
    "    is_raw=False\n",
    ")\n",
    "\n",
    "# Process RAW frame\n",
    "barbara_info_raw, cropped_raw, ts_raw = tag_detector.process_frame(\n",
    "    raw_frames[0].numpy(), pi_timestamps[0], detector, \n",
    "    margin_ratio=margin_ratio, \n",
    "    tag_ref_width=TAG_REF_WIDTH, \n",
    "    barbara_ref_size=BARBARA_REF_SIZE, \n",
    "    barbara_gap=BARBARA_GAP,\n",
    "    is_raw=True\n",
    ")\n",
    "\n",
    "# Process DV frame\n",
    "barbara_info_dv, cropped_dv, ts_dv = tag_detector.process_frame(\n",
    "    dv_frames[0].numpy(), dv_frames_timestamps[0], detector, \n",
    "    margin_ratio=margin_ratio, \n",
    "    tag_ref_width=TAG_REF_WIDTH, \n",
    "    barbara_ref_size=BARBARA_REF_SIZE, \n",
    "    barbara_gap=BARBARA_GAP,\n",
    "    is_raw=False\n",
    ")\n",
    "\n",
    "# Add the following three lines before displaying images\n",
    "def get_box_size(polygon):\n",
    "    if polygon is None:\n",
    "        return None\n",
    "    width = np.linalg.norm(polygon[1] - polygon[0])  # Bottom edge length\n",
    "    height = np.linalg.norm(polygon[2] - polygon[1])  # Right edge length\n",
    "    return (width, height)\n",
    "\n",
    "print(f\"RGB box size: {get_box_size(barbara_info_rgb['polygon'] if barbara_info_rgb else None)}\")\n",
    "print(f\"RAW box size: {get_box_size(barbara_info_raw['polygon'] if barbara_info_raw else None)}\")\n",
    "print(f\"DV box size: {get_box_size(barbara_info_dv['polygon'] if barbara_info_dv else None)}\")\n",
    "\n",
    "\n",
    "# Display single frame cropping effect\n",
    "plt.figure(figsize=(12, 12))\n",
    "# 1. RGB original image\n",
    "plt.subplot(3, 2, 1)\n",
    "frame_img_rgb = rgb_frames[0].numpy().copy()\n",
    "plt.imshow(frame_img_rgb)\n",
    "if barbara_info_rgb is not None:\n",
    "    poly = barbara_info_rgb['polygon']\n",
    "    x, y = poly[:,0], poly[:,1]\n",
    "    plt.plot(x, y, '-', color='lime', linewidth=4)\n",
    "    plt.plot([x[-1], x[0]], [y[-1], y[0]], '-', color='lime', linewidth=4)\n",
    "plt.title('RGB Frame with Barbara Region')\n",
    "plt.axis('off')\n",
    "\n",
    "# 2. RGB cropped\n",
    "plt.subplot(3, 2, 2)\n",
    "if cropped_rgb is not None:\n",
    "    plt.imshow(cropped_rgb)\n",
    "    plt.title('RGB Cropped Frame')\n",
    "else:\n",
    "    plt.title('RGB Cropped Frame (None)')\n",
    "plt.axis('off')\n",
    "\n",
    "# 3. RAW original image\n",
    "plt.subplot(3, 2, 3)\n",
    "frame_img_raw = raw_frames[0].numpy().copy()\n",
    "plt.imshow(frame_img_raw, cmap='gray')\n",
    "if barbara_info_raw is not None:\n",
    "    poly = barbara_info_raw['polygon']\n",
    "    x, y = poly[:,0], poly[:,1]\n",
    "    plt.plot(x, y, '-', color='lime', linewidth=4)\n",
    "    plt.plot([x[-1], x[0]], [y[-1], y[0]], '-', color='lime', linewidth=4)\n",
    "plt.title('RAW Frame with Barbara Region')\n",
    "plt.axis('off')\n",
    "\n",
    "# 4. RAW cropped\n",
    "plt.subplot(3, 2, 4)\n",
    "if cropped_raw is not None:\n",
    "    plt.imshow(cropped_raw, cmap='gray')\n",
    "    plt.title('RAW Cropped Frame')\n",
    "else:\n",
    "    plt.title('RAW Cropped Frame (None)')\n",
    "plt.axis('off')\n",
    "\n",
    "# 5. DV original image\n",
    "plt.subplot(3, 2, 5)\n",
    "frame_img_dv = dv_frames[0].numpy().copy()\n",
    "plt.imshow(frame_img_dv, cmap='gray')\n",
    "if barbara_info_dv is not None:\n",
    "    poly = barbara_info_dv['polygon']\n",
    "    x, y = poly[:,0], poly[:,1]\n",
    "    plt.plot(x, y, '-', color='lime', linewidth=4)\n",
    "    plt.plot([x[-1], x[0]], [y[-1], y[0]], '-', color='lime', linewidth=4)\n",
    "plt.title('DV Frame with Barbara Region')\n",
    "plt.axis('off')\n",
    "\n",
    "# 6. DV cropped\n",
    "plt.subplot(3, 2, 6)\n",
    "if cropped_dv is not None:\n",
    "    plt.imshow(cropped_dv, cmap='gray')\n",
    "    plt.title('DV Cropped Frame')\n",
    "else:\n",
    "    plt.title('DV Cropped Frame (None)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.15)  # Reduce column spacing\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Extract center point trajectories\n",
    "rgb_centers = np.array([info[0]['center'] for info in rgb_crops_info if info[0] is not None])\n",
    "raw_centers = np.array([info[0]['center'] for info in raw_crops_info if info[0] is not None])\n",
    "dv_centers  = np.array([info[0]['center'] for info in dv_crops_info  if info[0] is not None])\n",
    "\n",
    "\n",
    "# Extract angles\n",
    "rgb_angles = np.array([info[0]['angle'] for info in rgb_crops_info if info[0] is not None])\n",
    "raw_angles = np.array([info[0]['angle'] for info in raw_crops_info if info[0] is not None])\n",
    "dv_angles  = np.array([info[0]['angle'] for info in dv_crops_info  if info[0] is not None])\n",
    "\n",
    "rgb_times = [info[2] for info in rgb_crops_info if info[0] is not None]\n",
    "raw_times = [info[2] for info in raw_crops_info if info[0] is not None]\n",
    "dv_times  = [info[2] for info in dv_crops_info  if info[0] is not None]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# 1. Combine trajectories into one plot\n",
    "plt.subplot(2, 1, 1)\n",
    "s =1 # Point size\n",
    "lw = 1  # Line width\n",
    "\n",
    "if len(rgb_centers) > 0:\n",
    "    plt.plot(rgb_centers[:,0], rgb_centers[:,1], '-', color='red', lw=lw, label='RGB')\n",
    "    plt.scatter(rgb_centers[:,0], rgb_centers[:,1], color='red', s=s)\n",
    "\n",
    "if len(raw_centers) > 0:\n",
    "    plt.plot(raw_centers[:,0], raw_centers[:,1], '-', color='green', lw=lw, label='RAW')\n",
    "    plt.scatter(raw_centers[:,0], raw_centers[:,1], color='green', s=s)\n",
    "\n",
    "if len(dv_centers) > 0:\n",
    "    plt.plot(dv_centers[:,0], dv_centers[:,1], '-', color='blue', lw=lw, label='DV')\n",
    "    plt.scatter(dv_centers[:,0], dv_centers[:,1], color='blue', s=s)\n",
    "\n",
    "plt.title('Barbara Center Trajectories')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# 2. Combine angles vs time into one plot\n",
    "plt.subplot(2, 1, 2)\n",
    "s = 4  # Point size\n",
    "\n",
    "if len(rgb_angles) > 0:\n",
    "    plt.plot(rgb_times, rgb_angles, '-', color='red', lw=lw, label='RGB')\n",
    "    plt.scatter(rgb_times, rgb_angles, color='red', s=s)\n",
    "\n",
    "if len(raw_angles) > 0:\n",
    "    plt.plot(raw_times, raw_angles, '-', color='green', lw=lw, label='RAW')\n",
    "    plt.scatter(raw_times, raw_angles, color='green', s=s)\n",
    "\n",
    "if len(dv_angles) > 0:\n",
    "    plt.plot(dv_times, dv_angles, '-', color='blue', lw=lw, label='DV')\n",
    "    plt.scatter(dv_times, dv_angles, color='blue', s=s)\n",
    "\n",
    "plt.title('Barbara Angle vs Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Angle (deg)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playback Visualization of Filtered Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import datetime \n",
    "\n",
    "def play_filtered_events(events, interval_ms=33, window_size=(230, 230)):\n",
    "    \"\"\"\n",
    "    Play filtered event data\n",
    "    \n",
    "    Parameters:\n",
    "    events: Filtered event data (PyTorch tensor)\n",
    "    interval_ms: Time interval between frames (milliseconds)\n",
    "    window_size: Display window size\n",
    "    \"\"\"\n",
    "    # Create event accumulator\n",
    "    accumulator = dv.Accumulator(window_size)\n",
    "    \n",
    "    # Set accumulator parameters\n",
    "    accumulator.setEventContribution(0.25)\n",
    "    accumulator.setNeutralPotential(0.5)\n",
    "    accumulator.setMinPotential(0.0)\n",
    "    accumulator.setMaxPotential(1.0)\n",
    "    accumulator.setDecayFunction(dv.Accumulator.Decay.LINEAR)\n",
    "    accumulator.setDecayParam(1e-6)\n",
    "    accumulator.setSynchronousDecay(False)\n",
    "    accumulator.setIgnorePolarity(False)\n",
    "    \n",
    "    # Create preview window\n",
    "    cv2.namedWindow(\"Events Preview\", cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    # Create event slicer\n",
    "    slicer = dv.EventStreamSlicer()\n",
    "    \n",
    "    # Frame counter\n",
    "    frame_counter = 0\n",
    "    \n",
    "    def accumulate_events(event_slice):\n",
    "        nonlocal frame_counter\n",
    "        \n",
    "        # Pass event slice to accumulator\n",
    "        accumulator.accept(event_slice)\n",
    "        \n",
    "        # Generate frame\n",
    "        frame = accumulator.generateFrame()\n",
    "        \n",
    "        # Increment frame counter\n",
    "        frame_counter += 1\n",
    "        \n",
    "        # Display frame\n",
    "        cv2.imshow(\"Events Preview\", frame.image)\n",
    "        cv2.waitKey(2)\n",
    "    \n",
    "    # Set time interval\n",
    "    slicer.doEveryTimeInterval(datetime.timedelta(milliseconds=interval_ms), accumulate_events)\n",
    "    \n",
    "    print(\"Starting event data playback...\")\n",
    "    \n",
    "    # Get event data\n",
    "    # We need to convert PyTorch tensor to event format that dv library can process\n",
    "    # Process events in batches, 1000 events per batch\n",
    "    batch_size = 1000\n",
    "    total_events = len(events)\n",
    "    \n",
    "    for i in range(0, total_events, batch_size):\n",
    "        # Get current batch of events\n",
    "        batch_events = events[i:min(i+batch_size, total_events)]\n",
    "        \n",
    "        # Convert to format that dv library can process\n",
    "        batch = dv.EventStore()\n",
    "        for j in range(len(batch_events)):\n",
    "            event = batch_events[j]\n",
    "            x = int(event[0].item())\n",
    "            y = int(event[1].item())\n",
    "            timestamp = int(event[2].item())\n",
    "            polarity = int(event[3].item())\n",
    "            batch.push_back(dv.Event(x, y, timestamp, polarity))\n",
    "        \n",
    "        # Pass events to slicer\n",
    "        slicer.accept(batch)\n",
    "        \n",
    "        # Check if 'q' key is pressed to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    print(f\"Total frames: {frame_counter}\")\n",
    "    print(\"Event playback completed\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Play events\n",
    "# play_filtered_events(filtered_events_dv, 33, (DV_BOX_SIZE_FOR_EVENT, DV_BOX_SIZE_FOR_EVENT))\n",
    "play_filtered_events(filtered_events_raw, 33, (RAW_BOX_SIZE_FOR_EVENT, RAW_BOX_SIZE_FOR_EVENT))\n",
    "# play_filtered_events(filtered_events_rgb, 33, (RGB_BOX_SIZE_FOR_EVENT, RGB_BOX_SIZE_FOR_EVENT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
